{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Keras Deep Learning Model:__\n",
    "\n",
    "Doesn't work :D 25% accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pickle\n",
    "from keras.layers import Input, Dense, Add, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FeatureData/featuresnew.pk', 'rb') as file:\n",
    "    warren_features, warren_feature_names, warren_labels = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['sadness',\n",
       "  'joy',\n",
       "  'fear',\n",
       "  'disgust',\n",
       "  'anger',\n",
       "  'sentiment',\n",
       "  'character',\n",
       "  '#1job'],\n",
       " 1742,\n",
       " 5719)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warren_feature_names[:8], len(warren_features), len(warren_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren_features_train, warren_features_test, y_train, y_test = train_test_split(warren_features, warren_labels, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "warren_emot_mat = [i[:5] for i in warren_features_train]\n",
    "warren_sent_mat = [i[5] for i in warren_features_train]\n",
    "warren_char_mat = [i[6] for i in warren_features_train]\n",
    "warren_keys_mat = [i[7:] for i in warren_features_train]\n",
    "# [warren_features[:5], warren_features[5], warren_features[6], warren_features[7:]]\n",
    "warren_emot_mat_test= [i[:5] for i in warren_features_test]\n",
    "warren_sent_mat_test = [i[5] for i in warren_features_test]\n",
    "warren_char_mat_test = [i[6] for i in warren_features_test]\n",
    "warren_keys_mat_test= [i[7:] for i in warren_features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 581, 5, 5)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(warren_emot_mat), len(warren_emot_mat_test), len(warren_emot_mat[0]), len(warren_emot_mat_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + keras.backend.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = keras.backend.sum(keras.backend.round(keras.backend.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + keras.backend.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+keras.backend.epsilon()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A1 = Input(shape=(30,),name='A1')\n",
    "A2 = Dense(8, activation='relu',name='A2')(A1)\n",
    "A3 = Dense(30, activation='relu',name='A3')(A2)\n",
    "\n",
    "B2 = Dense(40, activation='relu',name='B2')(A2)\n",
    "B3 = Dense(30, activation='relu',name='B3')(B2)\n",
    "\n",
    "merged = Model(inputs=[A1],outputs=[A3,B3])\n",
    "plot_model(merged,to_file='demo.png',show_shapes=True)\n",
    "\n",
    "######################################################\n",
    "\n",
    "input1 = keras.layers.Input(shape=(16,))\n",
    "x1 = keras.layers.Dense(8, activation='relu')(input1)\n",
    "input2 = keras.layers.Input(shape=(32,))\n",
    "x2 = keras.layers.Dense(8, activation='relu')(input2)\n",
    "# equivalent to added = keras.layers.add([x1, x2])\n",
    "added = keras.layers.Add()([x1, x2])\n",
    "\n",
    "out = keras.layers.Dense(4)(added)\n",
    "model = keras.models.Model(inputs=[input1, input2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "emot1 = Input(shape=(5,),name='emot1')\n",
    "emot2 = Dense(2, activation=\"sigmoid\")(emot1)\n",
    "\n",
    "sent1 = Input(shape=(1,),name='sent1')\n",
    "\n",
    "char1 = Input(shape=(1,),name='char1')\n",
    "\n",
    "keys1 = Input(shape=(5712,),name='keys1')\n",
    "keys2 = Dense(60, activation='relu')(keys1)\n",
    "\n",
    "merged = Concatenate()([emot2, sent1, char1, keys2])\n",
    "merge_out = Dense(8)(merged)\n",
    "\n",
    "out = Dense(1)(merge_out)\n",
    "\n",
    "model = Model(inputs=[emot1, sent1, char1, keys1], outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "emot1 (InputLayer)              (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keys1 (InputLayer)              (None, 5712)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 2)            12          emot1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sent1 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char1 (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 60)           342780      keys1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 64)           0           dense_33[0][0]                   \n",
      "                                                                 sent1[0][0]                      \n",
      "                                                                 char1[0][0]                      \n",
      "                                                                 dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 8)            520         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 1)            9           dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 343,321\n",
      "Trainable params: 343,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1_m])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# compile the model using mean absolute percentage error as our loss,\n",
    "# implying that we seek to minimize the absolute percentage difference\n",
    "# between our price *predictions* and the *actual prices*\n",
    "opt = Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    " \n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit([trainAttrX, trainImagesX], trainY,\n",
    "          validation_data=([testAttrX, testImagesX], testY),\n",
    "          epochs=200, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5719"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(warren_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1161 samples, validate on 581 samples\n",
      "Epoch 1/100\n",
      "1161/1161 [==============================] - 1s 1ms/step - loss: -0.0348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: -0.4909 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1161/1161 [==============================] - 0s 420us/step - loss: -0.7181 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - val_loss: -0.9383 - val_acc: 0.0000e+00 - val_f1_m: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1161/1161 [==============================] - 1s 454us/step - loss: -1.1826 - acc: 0.0078 - f1_m: 0.0363 - val_loss: -0.6240 - val_acc: 0.0069 - val_f1_m: 0.0349\n",
      "Epoch 4/100\n",
      "1161/1161 [==============================] - 1s 433us/step - loss: -1.4109 - acc: 0.0112 - f1_m: 0.0439 - val_loss: -0.5155 - val_acc: 0.0241 - val_f1_m: 0.1151\n",
      "Epoch 5/100\n",
      "1161/1161 [==============================] - 1s 440us/step - loss: -1.7019 - acc: 0.0189 - f1_m: 0.0745 - val_loss: -1.0236 - val_acc: 0.0069 - val_f1_m: 0.0349\n",
      "Epoch 6/100\n",
      "1161/1161 [==============================] - 1s 552us/step - loss: -2.1803 - acc: 0.0396 - f1_m: 0.1488 - val_loss: -1.1150 - val_acc: 0.0155 - val_f1_m: 0.0652\n",
      "Epoch 7/100\n",
      "1161/1161 [==============================] - 1s 789us/step - loss: -2.8361 - acc: 0.1034 - f1_m: 0.3330 - val_loss: -1.6478 - val_acc: 0.0258 - val_f1_m: 0.0990\n",
      "Epoch 8/100\n",
      "1161/1161 [==============================] - 1s 601us/step - loss: -3.5534 - acc: 0.1904 - f1_m: 0.6823 - val_loss: -1.1808 - val_acc: 0.0706 - val_f1_m: 0.2757\n",
      "Epoch 9/100\n",
      "1161/1161 [==============================] - 1s 485us/step - loss: -3.7173 - acc: 0.2506 - f1_m: 0.8309 - val_loss: -1.2819 - val_acc: 0.1119 - val_f1_m: 0.4422\n",
      "Epoch 10/100\n",
      "1161/1161 [==============================] - 0s 430us/step - loss: -3.9483 - acc: 0.3023 - f1_m: 0.9377 - val_loss: -1.7915 - val_acc: 0.1050 - val_f1_m: 0.3810\n",
      "Epoch 11/100\n",
      "1161/1161 [==============================] - 1s 717us/step - loss: -4.0229 - acc: 0.2963 - f1_m: 0.8782 - val_loss: -1.6797 - val_acc: 0.1084 - val_f1_m: 0.3908\n",
      "Epoch 12/100\n",
      "1161/1161 [==============================] - 1s 454us/step - loss: -4.3623 - acc: 0.3463 - f1_m: 0.9849 - val_loss: -1.7322 - val_acc: 0.1239 - val_f1_m: 0.4414\n",
      "Epoch 13/100\n",
      "1161/1161 [==============================] - 1s 466us/step - loss: -4.4346 - acc: 0.3669 - f1_m: 1.1012 - val_loss: -1.5628 - val_acc: 0.1429 - val_f1_m: 0.5280\n",
      "Epoch 14/100\n",
      "1161/1161 [==============================] - 1s 441us/step - loss: -4.4834 - acc: 0.4083 - f1_m: 1.2322 - val_loss: -1.4476 - val_acc: 0.1566 - val_f1_m: 0.5766\n",
      "Epoch 15/100\n",
      "1161/1161 [==============================] - 1s 445us/step - loss: -4.5124 - acc: 0.4005 - f1_m: 1.1832 - val_loss: -1.5686 - val_acc: 0.1601 - val_f1_m: 0.5653\n",
      "Epoch 16/100\n",
      "1161/1161 [==============================] - 1s 561us/step - loss: -4.4852 - acc: 0.4496 - f1_m: 1.3503 - val_loss: -1.5295 - val_acc: 0.1945 - val_f1_m: 0.7393\n",
      "Epoch 17/100\n",
      "1161/1161 [==============================] - 1s 543us/step - loss: -4.5064 - acc: 0.4401 - f1_m: 1.2882 - val_loss: -1.5271 - val_acc: 0.1876 - val_f1_m: 0.6720\n",
      "Epoch 18/100\n",
      "1161/1161 [==============================] - 1s 785us/step - loss: -4.5625 - acc: 0.3411 - f1_m: 1.1085 - val_loss: -1.8245 - val_acc: 0.1704 - val_f1_m: 0.4997\n",
      "Epoch 19/100\n",
      "1161/1161 [==============================] - 1s 543us/step - loss: -4.7427 - acc: 0.5788 - f1_m: 1.8498 - val_loss: -1.2639 - val_acc: 0.3391 - val_f1_m: 1.4610\n",
      "Epoch 20/100\n",
      "1161/1161 [==============================] - 1s 591us/step - loss: -4.9317 - acc: 0.6357 - f1_m: 1.9388 - val_loss: -1.5731 - val_acc: 0.2960 - val_f1_m: 1.2296\n",
      "Epoch 21/100\n",
      "1161/1161 [==============================] - 1s 638us/step - loss: -5.0638 - acc: 0.6003 - f1_m: 1.7294 - val_loss: -1.6499 - val_acc: 0.2685 - val_f1_m: 1.0145\n",
      "Epoch 22/100\n",
      "1161/1161 [==============================] - 1s 792us/step - loss: -5.1406 - acc: 0.5676 - f1_m: 1.6266 - val_loss: -1.6620 - val_acc: 0.2530 - val_f1_m: 0.9231\n",
      "Epoch 23/100\n",
      "1161/1161 [==============================] - 1s 650us/step - loss: -5.0597 - acc: 0.4660 - f1_m: 1.4216 - val_loss: -1.5549 - val_acc: 0.2117 - val_f1_m: 0.6169\n",
      "Epoch 24/100\n",
      "1161/1161 [==============================] - 1s 507us/step - loss: -4.9289 - acc: 0.3239 - f1_m: 1.1948 - val_loss: -1.5438 - val_acc: 0.2306 - val_f1_m: 0.6800\n",
      "Epoch 25/100\n",
      "1161/1161 [==============================] - 1s 585us/step - loss: -5.7508 - acc: 0.4220 - f1_m: 1.3542 - val_loss: -1.5374 - val_acc: 0.2238 - val_f1_m: 0.6687\n",
      "Epoch 26/100\n",
      "1161/1161 [==============================] - 1s 539us/step - loss: -5.7734 - acc: 0.4866 - f1_m: 1.5187 - val_loss: -1.5229 - val_acc: 0.2496 - val_f1_m: 0.7964\n",
      "Epoch 27/100\n",
      "1161/1161 [==============================] - 1s 544us/step - loss: -5.8075 - acc: 0.4866 - f1_m: 1.5041 - val_loss: -1.6059 - val_acc: 0.2496 - val_f1_m: 0.7848\n",
      "Epoch 28/100\n",
      "1161/1161 [==============================] - 1s 632us/step - loss: -5.8010 - acc: 0.4806 - f1_m: 1.4986 - val_loss: -1.6425 - val_acc: 0.2444 - val_f1_m: 0.7626\n",
      "Epoch 29/100\n",
      "1161/1161 [==============================] - 1s 847us/step - loss: -5.8034 - acc: 0.4849 - f1_m: 1.5271 - val_loss: -1.5451 - val_acc: 0.2547 - val_f1_m: 0.8215\n",
      "Epoch 30/100\n",
      "1161/1161 [==============================] - 1s 722us/step - loss: -5.8117 - acc: 0.5082 - f1_m: 1.5966 - val_loss: -1.5582 - val_acc: 0.2547 - val_f1_m: 0.8235\n",
      "Epoch 31/100\n",
      "1161/1161 [==============================] - 1s 645us/step - loss: -5.8140 - acc: 0.4978 - f1_m: 1.5500 - val_loss: -1.5176 - val_acc: 0.2513 - val_f1_m: 0.8053\n",
      "Epoch 32/100\n",
      "1161/1161 [==============================] - 1s 492us/step - loss: -5.8027 - acc: 0.4918 - f1_m: 1.5431 - val_loss: -1.5507 - val_acc: 0.2496 - val_f1_m: 0.7772\n",
      "Epoch 33/100\n",
      "1161/1161 [==============================] - 1s 668us/step - loss: -5.8393 - acc: 0.4892 - f1_m: 1.5652 - val_loss: -1.5687 - val_acc: 0.2496 - val_f1_m: 0.7702\n",
      "Epoch 34/100\n",
      "1161/1161 [==============================] - 1s 776us/step - loss: -5.8583 - acc: 0.4823 - f1_m: 1.5083 - val_loss: -1.4970 - val_acc: 0.2530 - val_f1_m: 0.8090\n",
      "Epoch 35/100\n",
      "1161/1161 [==============================] - 1s 654us/step - loss: -5.8700 - acc: 0.5099 - f1_m: 1.5989 - val_loss: -1.5171 - val_acc: 0.2513 - val_f1_m: 0.8061\n",
      "Epoch 36/100\n",
      "1161/1161 [==============================] - 0s 424us/step - loss: -5.8729 - acc: 0.4987 - f1_m: 1.5420 - val_loss: -1.5103 - val_acc: 0.2530 - val_f1_m: 0.7975\n",
      "Epoch 37/100\n",
      "1161/1161 [==============================] - 0s 406us/step - loss: -5.8646 - acc: 0.5004 - f1_m: 1.5955 - val_loss: -1.5916 - val_acc: 0.2513 - val_f1_m: 0.8144\n",
      "Epoch 38/100\n",
      "1161/1161 [==============================] - 1s 540us/step - loss: -5.8741 - acc: 0.5125 - f1_m: 1.6139 - val_loss: -1.5139 - val_acc: 0.2530 - val_f1_m: 0.8151\n",
      "Epoch 39/100\n",
      "1161/1161 [==============================] - 1s 786us/step - loss: -5.8843 - acc: 0.5065 - f1_m: 1.5816 - val_loss: -1.4944 - val_acc: 0.2513 - val_f1_m: 0.8009\n",
      "Epoch 40/100\n",
      "1161/1161 [==============================] - 1s 670us/step - loss: -5.8343 - acc: 0.4789 - f1_m: 1.5036 - val_loss: -1.4650 - val_acc: 0.2754 - val_f1_m: 0.8836\n",
      "Epoch 41/100\n",
      "1161/1161 [==============================] - 1s 839us/step - loss: -5.9184 - acc: 0.5004 - f1_m: 1.5659 - val_loss: -1.4855 - val_acc: 0.2788 - val_f1_m: 0.8887\n",
      "Epoch 42/100\n",
      "1161/1161 [==============================] - 1s 665us/step - loss: -5.9195 - acc: 0.4935 - f1_m: 1.5730 - val_loss: -1.4844 - val_acc: 0.2754 - val_f1_m: 0.8688\n",
      "Epoch 43/100\n",
      "1161/1161 [==============================] - 1s 531us/step - loss: -5.9203 - acc: 0.4927 - f1_m: 1.5746 - val_loss: -1.4751 - val_acc: 0.2737 - val_f1_m: 0.8584\n",
      "Epoch 44/100\n",
      "1161/1161 [==============================] - 1s 496us/step - loss: -5.9105 - acc: 0.5220 - f1_m: 1.6216 - val_loss: -1.5852 - val_acc: 0.2840 - val_f1_m: 0.9401\n",
      "Epoch 45/100\n",
      "1161/1161 [==============================] - 0s 423us/step - loss: -5.9193 - acc: 0.5357 - f1_m: 1.6482 - val_loss: -1.5219 - val_acc: 0.2788 - val_f1_m: 0.9230\n",
      "Epoch 46/100\n",
      "1161/1161 [==============================] - 0s 428us/step - loss: -5.9205 - acc: 0.5263 - f1_m: 1.6785 - val_loss: -1.5243 - val_acc: 0.2788 - val_f1_m: 0.9201\n",
      "Epoch 47/100\n",
      "1161/1161 [==============================] - 0s 430us/step - loss: -5.9115 - acc: 0.5349 - f1_m: 1.8202 - val_loss: -1.5152 - val_acc: 0.2995 - val_f1_m: 0.9910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "1161/1161 [==============================] - 0s 403us/step - loss: -5.9193 - acc: 0.5495 - f1_m: 1.6947 - val_loss: -1.5308 - val_acc: 0.2978 - val_f1_m: 0.9844\n",
      "Epoch 49/100\n",
      "1161/1161 [==============================] - 1s 433us/step - loss: -5.9205 - acc: 0.5426 - f1_m: 1.7583 - val_loss: -1.5425 - val_acc: 0.2995 - val_f1_m: 0.9844\n",
      "Epoch 50/100\n",
      "1161/1161 [==============================] - 0s 403us/step - loss: -5.9212 - acc: 0.5426 - f1_m: 1.6938 - val_loss: -1.5257 - val_acc: 0.3012 - val_f1_m: 0.9846\n",
      "Epoch 51/100\n",
      "1161/1161 [==============================] - 0s 390us/step - loss: -5.9219 - acc: 0.5383 - f1_m: 1.6847 - val_loss: -1.5066 - val_acc: 0.2995 - val_f1_m: 0.9739\n",
      "Epoch 52/100\n",
      "1161/1161 [==============================] - 0s 384us/step - loss: -5.9224 - acc: 0.5323 - f1_m: 1.6451 - val_loss: -1.4904 - val_acc: 0.2995 - val_f1_m: 0.9706\n",
      "Epoch 53/100\n",
      "1161/1161 [==============================] - 0s 387us/step - loss: -5.9229 - acc: 0.5297 - f1_m: 1.7136 - val_loss: -1.4708 - val_acc: 0.2978 - val_f1_m: 0.9706\n",
      "Epoch 54/100\n",
      "1161/1161 [==============================] - 0s 388us/step - loss: -5.9233 - acc: 0.5228 - f1_m: 1.6883 - val_loss: -1.4502 - val_acc: 0.2943 - val_f1_m: 0.9599\n",
      "Epoch 55/100\n",
      "1161/1161 [==============================] - 0s 393us/step - loss: -5.9140 - acc: 0.5461 - f1_m: 1.6884 - val_loss: -1.6016 - val_acc: 0.3029 - val_f1_m: 1.0137\n",
      "Epoch 56/100\n",
      "1161/1161 [==============================] - 0s 392us/step - loss: -5.9215 - acc: 0.5685 - f1_m: 1.7330 - val_loss: -1.5669 - val_acc: 0.3029 - val_f1_m: 1.0088\n",
      "Epoch 57/100\n",
      "1161/1161 [==============================] - 0s 400us/step - loss: -5.9226 - acc: 0.5642 - f1_m: 1.7342 - val_loss: -1.5248 - val_acc: 0.3012 - val_f1_m: 0.9977\n",
      "Epoch 58/100\n",
      "1161/1161 [==============================] - 0s 400us/step - loss: -5.9231 - acc: 0.5504 - f1_m: 1.7152 - val_loss: -1.4481 - val_acc: 0.3046 - val_f1_m: 0.9994\n",
      "Epoch 59/100\n",
      "1161/1161 [==============================] - 0s 403us/step - loss: -5.9135 - acc: 0.5659 - f1_m: 1.7198 - val_loss: -1.5515 - val_acc: 0.3081 - val_f1_m: 1.0596\n",
      "Epoch 60/100\n",
      "1161/1161 [==============================] - 0s 401us/step - loss: -5.9230 - acc: 0.5788 - f1_m: 1.8257 - val_loss: -1.5656 - val_acc: 0.3115 - val_f1_m: 1.0476\n",
      "Epoch 61/100\n",
      "1161/1161 [==============================] - 0s 396us/step - loss: -5.9128 - acc: 0.5676 - f1_m: 1.8255 - val_loss: -1.5866 - val_acc: 0.3150 - val_f1_m: 1.0502\n",
      "Epoch 62/100\n",
      "1161/1161 [==============================] - 0s 395us/step - loss: -5.9234 - acc: 0.5711 - f1_m: 1.7774 - val_loss: -1.5730 - val_acc: 0.3150 - val_f1_m: 1.0512\n",
      "Epoch 63/100\n",
      "1161/1161 [==============================] - 0s 401us/step - loss: -5.9234 - acc: 0.5659 - f1_m: 1.8688 - val_loss: -1.5529 - val_acc: 0.3115 - val_f1_m: 1.0401\n",
      "Epoch 64/100\n",
      "1161/1161 [==============================] - 0s 400us/step - loss: -5.9133 - acc: 0.5788 - f1_m: 1.8236 - val_loss: -1.5099 - val_acc: 0.3890 - val_f1_m: 1.5305\n",
      "Epoch 65/100\n",
      "1161/1161 [==============================] - 0s 401us/step - loss: -5.8943 - acc: 0.6865 - f1_m: 2.0775 - val_loss: -1.5184 - val_acc: 0.3941 - val_f1_m: 1.4882\n",
      "Epoch 66/100\n",
      "1161/1161 [==============================] - 0s 402us/step - loss: -5.9159 - acc: 0.6641 - f1_m: 1.9823 - val_loss: -1.4635 - val_acc: 0.3907 - val_f1_m: 1.4458\n",
      "Epoch 67/100\n",
      "1161/1161 [==============================] - 0s 395us/step - loss: -5.9191 - acc: 0.6546 - f1_m: 2.0495 - val_loss: -1.4484 - val_acc: 0.3873 - val_f1_m: 1.4258\n",
      "Epoch 68/100\n",
      "1161/1161 [==============================] - 1s 454us/step - loss: -5.9206 - acc: 0.6486 - f1_m: 2.0198 - val_loss: -1.4726 - val_acc: 0.3873 - val_f1_m: 1.4185\n",
      "Epoch 69/100\n",
      "1161/1161 [==============================] - 1s 464us/step - loss: -5.9123 - acc: 0.6408 - f1_m: 2.0543 - val_loss: -1.4731 - val_acc: 0.3855 - val_f1_m: 1.4185\n",
      "Epoch 70/100\n",
      "1161/1161 [==============================] - 0s 398us/step - loss: -5.9211 - acc: 0.6581 - f1_m: 2.0259 - val_loss: -1.4361 - val_acc: 0.3924 - val_f1_m: 1.4598\n",
      "Epoch 71/100\n",
      "1161/1161 [==============================] - 0s 400us/step - loss: -5.9219 - acc: 0.6555 - f1_m: 1.9849 - val_loss: -1.4542 - val_acc: 0.3924 - val_f1_m: 1.4512\n",
      "Epoch 72/100\n",
      "1161/1161 [==============================] - 0s 401us/step - loss: -5.9225 - acc: 0.6537 - f1_m: 2.0132 - val_loss: -1.4723 - val_acc: 0.3924 - val_f1_m: 1.4512\n",
      "Epoch 73/100\n",
      "1161/1161 [==============================] - 0s 393us/step - loss: -5.9230 - acc: 0.6443 - f1_m: 2.0257 - val_loss: -1.4906 - val_acc: 0.3941 - val_f1_m: 1.4303\n",
      "Epoch 74/100\n",
      "1161/1161 [==============================] - 0s 398us/step - loss: -5.9235 - acc: 0.6400 - f1_m: 2.3732 - val_loss: -1.4754 - val_acc: 0.3924 - val_f1_m: 1.4269\n",
      "Epoch 75/100\n",
      "1161/1161 [==============================] - 0s 401us/step - loss: -5.8089 - acc: 0.4858 - f1_m: 1.7813 - val_loss: -1.1076 - val_acc: 0.2633 - val_f1_m: 0.8146\n",
      "Epoch 76/100\n",
      "1161/1161 [==============================] - 0s 397us/step - loss: -5.8166 - acc: 0.4083 - f1_m: 1.6192 - val_loss: -1.4736 - val_acc: 0.3133 - val_f1_m: 1.0424\n",
      "Epoch 77/100\n",
      "1161/1161 [==============================] - 0s 396us/step - loss: -6.0238 - acc: 0.5668 - f1_m: 1.9509 - val_loss: -1.6076 - val_acc: 0.3425 - val_f1_m: 1.1702\n",
      "Epoch 78/100\n",
      "1161/1161 [==============================] - 0s 394us/step - loss: -6.0256 - acc: 0.5780 - f1_m: 1.9649 - val_loss: -1.6329 - val_acc: 0.3408 - val_f1_m: 1.1708\n",
      "Epoch 79/100\n",
      "1161/1161 [==============================] - 0s 394us/step - loss: -6.0364 - acc: 0.5866 - f1_m: 1.9249 - val_loss: -1.6332 - val_acc: 0.3391 - val_f1_m: 1.1700\n",
      "Epoch 80/100\n",
      "1161/1161 [==============================] - 0s 400us/step - loss: -6.0368 - acc: 0.5831 - f1_m: 1.9409 - val_loss: -1.6329 - val_acc: 0.3408 - val_f1_m: 1.1717\n",
      "Epoch 81/100\n",
      "1161/1161 [==============================] - 1s 439us/step - loss: -6.0370 - acc: 0.5823 - f1_m: 1.8943 - val_loss: -1.6198 - val_acc: 0.3408 - val_f1_m: 1.1681\n",
      "Epoch 82/100\n",
      "1161/1161 [==============================] - 1s 595us/step - loss: -6.0372 - acc: 0.5788 - f1_m: 1.9406 - val_loss: -1.6140 - val_acc: 0.3408 - val_f1_m: 1.1646\n",
      "Epoch 83/100\n",
      "1161/1161 [==============================] - 1s 736us/step - loss: -6.0374 - acc: 0.5780 - f1_m: 1.9414 - val_loss: -1.5787 - val_acc: 0.3425 - val_f1_m: 1.1666\n",
      "Epoch 84/100\n",
      "1161/1161 [==============================] - 1s 558us/step - loss: -6.0376 - acc: 0.5754 - f1_m: 1.8991 - val_loss: -1.5745 - val_acc: 0.3460 - val_f1_m: 1.1626\n",
      "Epoch 85/100\n",
      "1161/1161 [==============================] - 1s 468us/step - loss: -6.0278 - acc: 0.5771 - f1_m: 1.9729 - val_loss: -1.6311 - val_acc: 0.3477 - val_f1_m: 1.1827\n",
      "Epoch 86/100\n",
      "1161/1161 [==============================] - 0s 421us/step - loss: -6.0371 - acc: 0.5891 - f1_m: 1.8638 - val_loss: -1.6305 - val_acc: 0.3477 - val_f1_m: 1.1827\n",
      "Epoch 87/100\n",
      "1161/1161 [==============================] - 0s 429us/step - loss: -6.0373 - acc: 0.5883 - f1_m: 1.8709 - val_loss: -1.6306 - val_acc: 0.3477 - val_f1_m: 1.1827\n",
      "Epoch 88/100\n",
      "1161/1161 [==============================] - 1s 431us/step - loss: -6.0374 - acc: 0.5874 - f1_m: 1.9572 - val_loss: -1.6305 - val_acc: 0.3477 - val_f1_m: 1.1827\n",
      "Epoch 89/100\n",
      "1161/1161 [==============================] - 1s 433us/step - loss: -6.0375 - acc: 0.5840 - f1_m: 1.9300 - val_loss: -1.6141 - val_acc: 0.3511 - val_f1_m: 1.1862\n",
      "Epoch 90/100\n",
      "1161/1161 [==============================] - 1s 438us/step - loss: -6.0376 - acc: 0.5831 - f1_m: 1.9262 - val_loss: -1.5971 - val_acc: 0.3511 - val_f1_m: 1.1862\n",
      "Epoch 91/100\n",
      "1161/1161 [==============================] - 1s 833us/step - loss: -6.0377 - acc: 0.5823 - f1_m: 2.0179 - val_loss: -1.6098 - val_acc: 0.3494 - val_f1_m: 1.1807\n",
      "Epoch 92/100\n",
      "1161/1161 [==============================] - 1s 730us/step - loss: -6.0378 - acc: 0.5823 - f1_m: 1.9241 - val_loss: -1.5760 - val_acc: 0.3477 - val_f1_m: 1.1746\n",
      "Epoch 93/100\n",
      "1161/1161 [==============================] - 1s 514us/step - loss: -6.0379 - acc: 0.5788 - f1_m: 1.9394 - val_loss: -1.5711 - val_acc: 0.3477 - val_f1_m: 1.1721\n",
      "Epoch 94/100\n",
      "1161/1161 [==============================] - 1s 577us/step - loss: -6.0379 - acc: 0.5771 - f1_m: 1.9714 - val_loss: -1.5684 - val_acc: 0.3477 - val_f1_m: 1.1721\n",
      "Epoch 95/100\n",
      "1161/1161 [==============================] - 1s 576us/step - loss: -6.0380 - acc: 0.5762 - f1_m: 1.8950 - val_loss: -1.5666 - val_acc: 0.3460 - val_f1_m: 1.1679\n",
      "Epoch 96/100\n",
      "1161/1161 [==============================] - 1s 562us/step - loss: -6.0381 - acc: 0.5728 - f1_m: 465118.1824 - val_loss: -1.5481 - val_acc: 0.3442 - val_f1_m: 1.1636\n",
      "Epoch 97/100\n",
      "1161/1161 [==============================] - 1s 576us/step - loss: -6.0381 - acc: 0.5736 - f1_m: 1.9643 - val_loss: -1.5459 - val_acc: 0.3442 - val_f1_m: 1.1622\n",
      "Epoch 98/100\n",
      "1161/1161 [==============================] - 1s 614us/step - loss: -6.0382 - acc: 0.5719 - f1_m: 1.9480 - val_loss: -1.5441 - val_acc: 0.3442 - val_f1_m: 1.1622\n",
      "Epoch 99/100\n",
      "1161/1161 [==============================] - 1s 577us/step - loss: -6.0382 - acc: 0.5711 - f1_m: 1.9223 - val_loss: -1.5412 - val_acc: 0.3425 - val_f1_m: 1.1506\n",
      "Epoch 100/100\n",
      "1161/1161 [==============================] - 1s 582us/step - loss: -6.0383 - acc: 0.5685 - f1_m: 1.9597 - val_loss: -1.5371 - val_acc: 0.3408 - val_f1_m: 1.1456\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit([warren_emot_mat, warren_sent_mat, warren_char_mat, warren_keys_mat],\n",
    "                 y_train,\n",
    "                 epochs=100,\n",
    "                 batch_size=16,\n",
    "                 validation_data=([warren_emot_mat_test, warren_sent_mat_test,\n",
    "                                  warren_char_mat_test, warren_keys_mat_test],y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_29/kernel:0' shape=(5, 2) dtype=float32_ref>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'f1_m': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'loss': [-3.2407888248662022,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888255011383,\n",
       "  -3.240788822326457,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888197867116,\n",
       "  -3.240788826136075,\n",
       "  -3.2407888172469668,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888197867116,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888210565843,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888172469668,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888235963296,\n",
       "  -3.2407888210565843,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888210565843,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888235963296,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888210565843,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888197867116,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888235963296,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888210565843,\n",
       "  -3.240788805183177,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888185168394,\n",
       "  -3.240788822326457,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888197867116,\n",
       "  -3.240788805183177,\n",
       "  -3.2407888235963296,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888210565843,\n",
       "  -3.240788805183177,\n",
       "  -3.2407888235963296,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888210565843,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888255011383,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888197867116,\n",
       "  -3.2407888185168394,\n",
       "  -3.2407888172469668,\n",
       "  -3.2407888210565843]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
